import cv2
from deepface import DeepFace

# Initialize the webcam
cap = cv2.VideoCapture(0)

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    
    # Use DeepFace to analyze emotions
    try:
        results = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)
        
        # Check if results is a list (for multiple faces) or a dictionary (for a single face)
        if isinstance(results, list):
            for result in results:
                emotion = result['dominant_emotion']
                x, y, w, h = result['region']['x'], result['region']['y'], result['region']['w'], result['region']['h']
                
                # Draw rectangle around the face
                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
                
                # Draw text for the detected emotion
                cv2.putText(frame, f"Emotion: {emotion}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        else:
            # Single face detected, results is a dictionary
            emotion = results['dominant_emotion']
            x, y, w, h = results['region']['x'], results['region']['y'], results['region']['w'], results['region']['h']
            
            # Draw rectangle around the face
            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            
            # Draw text for the detected emotion
            cv2.putText(frame, f"Emotion: {emotion}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

    except Exception as e:
        print("Face not detected or error in emotion detection:", e)
    
    # Display the resulting frame
    cv2.imshow('Emotion Detector', frame)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the capture and close the window
cap.release()
cv2.destroyAllWindows()
